{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029f9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56fab34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_A = StableDiffusionPipeline.from_pretrained(\n",
    "#     \"CompVis/stable-diffusion-v1-4\", \n",
    "#     torch_dtype=torch.float32)\n",
    "\n",
    "# pipe_B = StableDiffusionPipeline.from_pretrained(\n",
    "#     \"runwayml/stable-diffusion-v1-5\", \n",
    "#     torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414a49cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7883\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For asdf, you preferred A\n",
      "For apple, you preferred B\n"
     ]
    }
   ],
   "source": [
    "def infer(prompt, steps): \n",
    "    \n",
    "    # this is the actual use of the huggingface pipe\n",
    "    # for now, comment this out, and instead\n",
    "    # load test-images directly\n",
    "    \n",
    "#     scale = 25\n",
    "#     seed = 123456789\n",
    "#     generator = torch.Generator(device=device).manual_seed(seed)\n",
    "#     images_list_A = pipe_A(\n",
    "#         [prompt] * samples,\n",
    "#         num_inference_steps=steps,\n",
    "#         guidance_scale=scale,\n",
    "#         generator=generator,\n",
    "#     )\n",
    "#     images_list_B = pipe_B(\n",
    "#         [prompt] * samples,\n",
    "#         num_inference_steps=steps,\n",
    "#         guidance_scale=scale,\n",
    "#         generator=generator,\n",
    "#     )\n",
    "#     images_A, images_B = [], []\n",
    "#     for i, image in enumerate(images_list_A[\"sample\"]):\n",
    "#         image.save(f\"gradio_outputs/model_A/{prompt}_{i}.png\")\n",
    "#         images_A.append(image)\n",
    "#     for i, image in enumerate(images_list_B[\"sample\"]):\n",
    "#         image.save(f\"gradio_outputs/model_B/{prompt}_{i}.png\")\n",
    "#         images_B.append(image)\n",
    "#     return images_A + images_B\n",
    "\n",
    "    # load test images directly instead of using hugginface pipe\n",
    "    image_list_A = [Image.open(\"sample_img_A.png\")]*samples\n",
    "    image_list_B = [Image.open(\"sample_img_B.png\")]*samples\n",
    "    for i, image in enumerate(image_list_A):\n",
    "        image.save(f\"gradio_outputs/model_A/{prompt}_{i}.png\")\n",
    "    for i, image in enumerate(image_list_B):\n",
    "        image.save(f\"gradio_outputs/model_B/{prompt}_{i}.png\")\n",
    "    return image_list_A + image_list_B\n",
    "\n",
    "\n",
    "def give_feedback(prompt, better_model):\n",
    "    print(f\"For {prompt}, you preferred {better_model}\")\n",
    "    \n",
    "#     connection = psycopg2.connect(user=\"postgresGradiff\",\n",
    "#                                   password=\"DatathonGradioDiffusion2022\",\n",
    "#                                   host=\"http://database-ak-1.cjpo4rqs9rfq.us-east-2.rds.amazonaws.com/\",\n",
    "#                                   port=\"8080\",\n",
    "#                                   database=\"postgres_db\")\n",
    "#     cursor = connection.cursor()\n",
    "\n",
    "#     postgres_insert_query = \"\"\" INSERT INTO diffusion_compare (PROMPT, WINNER) VALUES (%s,%s)\"\"\"\n",
    "#     record_to_insert = (prompt, better_model)\n",
    "#     cursor.execute(postgres_insert_query, record_to_insert)\n",
    "\n",
    "#     connection.commit()\n",
    "\n",
    "samples = 3\n",
    "device = \"cpu\"\n",
    "block = gr.Blocks()\n",
    "\n",
    "with block:\n",
    "    with gr.Group():\n",
    "        with gr.Box():\n",
    "            with gr.Row().style(equal_height=True):\n",
    "                text = gr.Textbox(\n",
    "                    label=\"Enter your prompt\",\n",
    "                    show_label=False,\n",
    "                    max_lines=1,\n",
    "                    placeholder=\"Enter your prompt\",\n",
    "                )\n",
    "                btn = gr.Button(\"Generate images\")\n",
    "                \n",
    "        gallery = gr.Gallery(\n",
    "            label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n",
    "        ).style(grid=[6], height=\"auto\")\n",
    "\n",
    "        with gr.Row(elem_id=\"options\"):\n",
    "            steps = gr.Slider(label=\"Steps\", minimum=1, maximum=50, value=2, step=1)\n",
    "        text.submit(infer, inputs=[text, steps], outputs=gallery)\n",
    "        btn.click(infer, inputs=[text, steps], outputs=gallery)\n",
    "        with gr.Box():\n",
    "            with gr.Row().style(equal_height=True):\n",
    "                feedback_text = gr.Textbox(\n",
    "                    label=\"Give feedback\",\n",
    "                    show_label=False,\n",
    "                    max_lines=2,\n",
    "                    placeholder=\"Which model did better, A or B?\",\n",
    "                )\n",
    "                feedback_btn = gr.Button(\"Submit feedback\")\n",
    "        feedback_text.submit(give_feedback, inputs=[text, feedback_text], outputs=gallery)\n",
    "        feedback_btn.click(give_feedback, inputs=[text, feedback_text], outputs=gallery)\n",
    "        \n",
    "block.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411aee12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
